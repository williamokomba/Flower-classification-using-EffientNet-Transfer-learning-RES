{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaGQ5bBskKmWu+uZ0OtN5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamokomba/Flower-classification-using-EffientNet-Transfer-learning-RES/blob/main/flower_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flower Image  Classification using EfficientNet Transfer learning"
      ],
      "metadata": {
        "id": "HbVPzc1_6OXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. load using API token from kaggle\n",
        "2. visualize the images\n",
        "3. data augmentation\n",
        "4. train test split\n",
        "5. building EfficientNet model\n",
        "6. prediction and evaluation\n"
      ],
      "metadata": {
        "id": "e35EXbBB2T7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "About Dataset\n",
        "\n",
        "Context\n",
        "\n",
        "This dataset belongs to DPhi Data Sprint #25: Flower Recognition. The dataset contains raw jpeg images of five types of flowers.\n",
        "\n",
        "* daisy\n",
        "* dandelion\n",
        "* rose\n",
        "* sunflower\n",
        "* tulip\n",
        "\n",
        "Content\n",
        "\n",
        "* train - contains all the images that are to be used for training your model.\n",
        "  In this folder you will find five folders namely - 'daisy', 'dandelion', 'rose', 'sunflower' and 'tulip' which contain the images of the respective flowers\n",
        "* test - contains 924 flowers images. For these images you are required to make predictions as the respective flower names - 'daisy', 'dandelion', 'rose', 'sunflower' and 'tulip'\n",
        "* Testing_set_flower.csv - this is the order of the predictions for each image that is to be submitted on the platform. Make sure the predictions you download are with their image's filename in the same order as given in this file."
      ],
      "metadata": {
        "id": "V9bQ0TaE3UYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import dependences\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import cv2\n",
        "#!pip install imgaug\n",
        "import imgaug.augmenters as iaa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "8FBehfApkd7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading data directly from kaggle\n",
        "# Create API key\n",
        "#install kaggle library\n",
        "#!pip install kaggle\n"
      ],
      "metadata": {
        "id": "KE6FWxbtcNvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuring the path of kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ke7CiWtsdUEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[flower dataset kaggle link](https://www.kaggle.com/datasets/imsparsh/flowers-dataset)Import flower dataset api"
      ],
      "metadata": {
        "id": "11K1Iun-eOwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#API to fetch the dataset from kaggle\n",
        "!kaggle datasets download -d imsparsh/flowers-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdCr4yY06io",
        "outputId": "3d9cf4e2-6162-4b62-a1b5-14a51009f186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/imsparsh/flowers-dataset\n",
            "License(s): CC0-1.0\n",
            "flowers-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the compresed sentiment dataset\n",
        "from zipfile import ZipFile\n",
        "file_name = \"flowers-dataset.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2gYChjs1UBa",
        "outputId": "b9301223-9b6e-41b8-c2d5-87701176bcd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename train to flowwrs and Create it base Directory\n",
        "#import os\n",
        "os.rename('train', 'flowers')\n",
        "datadir = '/content/flowers'\n",
        "Categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1htx7g5G1ius",
        "outputId": "2afe3703-6234-4a38-dedc-f106679e1fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 39] Directory not empty: 'train' -> 'flowers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-93fbf4febda4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Rename train to flowwrs and Create it base Directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#import os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flowers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdatadir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/flowers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'daisy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dandelion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sunflower'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tulip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: 'train' -> 'flowers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the random images from each folder\n",
        "for category in Categories:\n",
        "    path = os.path.join(datadir, category)\n",
        "    imgs = os.listdir(path)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(10, 6))\n",
        "    fig.suptitle(f'{category}', fontsize= 15)   # Use suptitle to set the figure title\n",
        "\n",
        "    # Iterate over the 3 random images in each folder\n",
        "    for i in range(3):\n",
        "        img_name = imgs[np.random.randint(0, len(imgs))]\n",
        "        img_path = os.path.join(path, img_name)\n",
        "        img = plt.imread(img_path)\n",
        "\n",
        "        #Read the images from the path\n",
        "        image_array = cv2.imread(img_path)\n",
        "\n",
        "        #convert BGR to RGB color format\n",
        "        image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        #show image\n",
        "        axes[i].imshow(image_rgb)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4e-1FkEXBjDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Augmentation\n",
        "\n",
        "Data augmentation increases the accuracy of the model"
      ],
      "metadata": {
        "id": "NyEGAABEEiZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to count images in each folder to ensure that augmentation took place\n",
        "\n",
        "def count_images(directory):\n",
        "    for category in Categories:\n",
        "        path = os.path.join(directory, category)\n",
        "        num_images = len(os.listdir(path))\n",
        "        print(f'{category}: {num_images} images')"
      ],
      "metadata": {
        "id": "0_7N4zt5Ehar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count original images in each category\n",
        "count_images(datadir)"
      ],
      "metadata": {
        "id": "3eK2u8zzFpIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "aug = iaa.Sequential([\n",
        "#horizontal flips\n",
        "iaa.Fliplr(0.5),\n",
        "# randomly croping images upto 10% os it's size\n",
        "iaa.Crop(percent = (0, 0.1)),\n",
        "# scaling the image between 80% and 120% and rotating it between -25 to 25\n",
        "iaa.Affine(scale = (0.8, 1.2), rotate = (-25, 25)),\n",
        "# changing the brightness of the images\n",
        "iaa.Multiply((0.8, 1.2)),\n",
        "# adjusting the contrast of the images\n",
        "iaa.LinearContrast((0.75, 1.5))\n",
        "])\n",
        "\n",
        "#create a function to augment the images\n",
        "def augment_images(directory, Categories):\n",
        "    for category in Categories:\n",
        "        path = os.path.join(directory, category)\n",
        "        for filename in os.listdir(path):\n",
        "            img = cv2.imread(os.path.join(path, filename))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            augmented_img = aug.augment_image(img)\n",
        "\n",
        "#create a new file to hold uagmented images and then add them to original folder\n",
        "            new_filename = os.path.splitext(filename)[0] + '_augmented' + os.path.splitext(filename)[1] # Indent this line to be inside the loop\n",
        "            cv2.imwrite(os.path.join(path, new_filename), augmented_img) # Indent this line to be inside the loop\n",
        "\n",
        "#apply the function to all the images\n",
        "augment_images(datadir, Categories)"
      ],
      "metadata": {
        "id": "HDiIAhSEGcQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the new total images\n",
        "count_images(datadir)"
      ],
      "metadata": {
        "id": "8tE2Tct_H9DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resizing the images to 224"
      ],
      "metadata": {
        "id": "nfftL6lyplx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing the images to 224\n",
        "#Current size\n",
        "image_array.shape\n"
      ],
      "metadata": {
        "id": "Jltyh8sBn3gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resize to 224\n",
        "IMG_SIZE = 224\n",
        "new_array = cv2.resize(image_array, (IMG_SIZE, IMG_SIZE))\n",
        "new_array.shape"
      ],
      "metadata": {
        "id": "mJPqE0Qjp80F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize\n",
        "#change to rgb\n",
        "new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
        "#visualize\n",
        "plt.imshow(new_array);"
      ],
      "metadata": {
        "id": "qZksO7INqOdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training data"
      ],
      "metadata": {
        "id": "OC9iMRIgrAfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating training data and target\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in Categories:\n",
        "        path = os.path.join(datadir, category)\n",
        "        labels = Categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img))\n",
        "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, labels])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()"
      ],
      "metadata": {
        "id": "q2iPXgimq1MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check training data\n",
        "len(training_data)"
      ],
      "metadata": {
        "id": "4gV499pwsKRf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}